{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3f3336",
   "metadata": {},
   "source": [
    "This notebook creates the following tables:\n",
    "\n",
    "- publications\n",
    "- zenodo works\n",
    "- people on publications\n",
    "- people on zenodo works\n",
    "- citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91ae79",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b74e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pyalex import Works, Authors, Sources, Institutions, Topics, Publishers, Funders\n",
    "from pyalex import config\n",
    "from tqdm import tqdm \n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393ec8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import config\n",
    "\n",
    "config.email = \"rde6mn@virginia.edu\"\n",
    "config.max_retries = 5\n",
    "config.retry_backoff_factor = 0.1\n",
    "config.retry_http_codes = [429, 500, 503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5ca3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\1365623536.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  pub_tracker = pd.read_excel('Data\\Preliminary Work Data\\publication_tracker_icor_250916.xlsx')\n"
     ]
    }
   ],
   "source": [
    "pub_tracker = pd.read_excel('Data\\Preliminary Work Data\\publication_tracker_icor_250916.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab18bf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\3237962931.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  zenodo = pd.read_excel('Data\\Preliminary Work Data\\zenodo_dois.xlsx')\n"
     ]
    }
   ],
   "source": [
    "zenodo = pd.read_excel('Data\\Preliminary Work Data\\zenodo_dois.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877450d",
   "metadata": {},
   "source": [
    "## Get openalex id for work and lists of names, open alex ids, and orcids for people on publications with a doi_pub (for published works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ec6b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\4212284531.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'W4391629214' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  pub_tracker.at[idx, 'OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DOI 10.1177/2515256423116249: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.1177%2F2515256423116249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize your new columns\n",
    "pub_tracker['OpenAlex_ID'] = np.nan\n",
    "pub_tracker['ListofAlexIds'] = [[] for _ in range(len(pub_tracker))]\n",
    "pub_tracker['ListofNames'] = [[] for _ in range(len(pub_tracker))]\n",
    "pub_tracker['ListofOrcids'] = [[] for _ in range(len(pub_tracker))]\n",
    "\n",
    "# Iterate through the DOIs\n",
    "for idx, row in pub_tracker.iterrows():\n",
    "    doi_suffix = row['doi_pub']\n",
    "    if pd.notna(doi_suffix):\n",
    "        try:\n",
    "            doi_url = f\"https://doi.org/{doi_suffix}\"\n",
    "            work_json = Works()[doi_url]\n",
    "\n",
    "            # Extract OpenAlex ID\n",
    "            work_id = work_json.get('id', '')\n",
    "            if work_id.startswith(\"https://openalex.org/\"):\n",
    "                pub_tracker.at[idx, 'OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n",
    "\n",
    "            # Extract authorship information\n",
    "            alex_ids = []\n",
    "            names = []\n",
    "            orcids = []\n",
    "\n",
    "            for author_info in work_json.get('authorships', []):\n",
    "                author = author_info.get('author', {})\n",
    "\n",
    "                # Extract and clean author ID\n",
    "                author_id = author.get('id', '')\n",
    "                if author_id.startswith(\"https://openalex.org/\"):\n",
    "                    alex_ids.append(author_id.replace(\"https://openalex.org/\", \"\"))\n",
    "                else:\n",
    "                    alex_ids.append(None)\n",
    "\n",
    "                # Extract name\n",
    "                names.append(author.get('display_name', None))\n",
    "\n",
    "                # Extract and clean ORCID\n",
    "                orcid = author.get('orcid', '')\n",
    "                if orcid and orcid.startswith(\"https://orcid.org/\"):\n",
    "                    orcids.append(orcid.replace(\"https://orcid.org/\", \"\"))\n",
    "                else:\n",
    "                    orcids.append(None)\n",
    "\n",
    "            pub_tracker.at[idx, 'ListofAlexIds'] = alex_ids\n",
    "            pub_tracker.at[idx, 'ListofNames'] = names\n",
    "            pub_tracker.at[idx, 'ListofOrcids'] = orcids\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOI {doi_suffix}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f906d",
   "metadata": {},
   "source": [
    "## Get openalex id for work and lists of names, open alex ids, and orcids for people on publications with a doi_pre (for preprint works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca14f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\2146109281.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'W3186738626' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  pub_tracker.at[idx, 'Pre_OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DOI NA_review: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2FNA_review\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize your new columns\n",
    "pub_tracker['Pre_OpenAlex_ID'] = np.nan\n",
    "pub_tracker['Pre_ListofAlexIds'] = [[] for _ in range(len(pub_tracker))]\n",
    "pub_tracker['Pre_ListofNames'] = [[] for _ in range(len(pub_tracker))]\n",
    "pub_tracker['Pre_ListofOrcids'] = [[] for _ in range(len(pub_tracker))]\n",
    "\n",
    "# Iterate through the DOIs only for rows where OpenAlex_ID is missing\n",
    "for idx, row in pub_tracker.iterrows():\n",
    "    if pd.isna(row.get('OpenAlex_ID')) or row.get('OpenAlex_ID') == \"\":\n",
    "        doi_suffix = row.get('doi_pre')\n",
    "        if pd.notna(doi_suffix):\n",
    "            try:\n",
    "                doi_url = f\"https://doi.org/{doi_suffix}\"\n",
    "                work_json = Works()[doi_url]\n",
    "\n",
    "                # Extract OpenAlex ID\n",
    "                work_id = work_json.get('id', '')\n",
    "                if work_id.startswith(\"https://openalex.org/\"):\n",
    "                    pub_tracker.at[idx, 'Pre_OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n",
    "\n",
    "                # Extract authorship information\n",
    "                alex_ids = []\n",
    "                names = []\n",
    "                orcids = []\n",
    "\n",
    "                for author_info in work_json.get('authorships', []):\n",
    "                    author = author_info.get('author', {})\n",
    "\n",
    "                    # Extract and clean author ID\n",
    "                    author_id = author.get('id', '')\n",
    "                    if author_id.startswith(\"https://openalex.org/\"):\n",
    "                        alex_ids.append(author_id.replace(\"https://openalex.org/\", \"\"))\n",
    "                    else:\n",
    "                        alex_ids.append(None)\n",
    "\n",
    "                    # Extract name\n",
    "                    names.append(author.get('display_name', None))\n",
    "\n",
    "                    # Extract and clean ORCID\n",
    "                    orcid = author.get('orcid', '')\n",
    "                    if orcid and orcid.startswith(\"https://orcid.org/\"):\n",
    "                        orcids.append(orcid.replace(\"https://orcid.org/\", \"\"))\n",
    "                    else:\n",
    "                        orcids.append(None)\n",
    "\n",
    "                pub_tracker.at[idx, 'Pre_ListofAlexIds'] = alex_ids\n",
    "                pub_tracker.at[idx, 'Pre_ListofNames'] = names\n",
    "                pub_tracker.at[idx, 'Pre_ListofOrcids'] = orcids\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing DOI {doi_suffix}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b82da9b",
   "metadata": {},
   "source": [
    "## Merge publication and preprint information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba338194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge OpenAlex_ID columns (scalar values)\n",
    "pub_tracker['OpenAlex_ID'] = pub_tracker['OpenAlex_ID'].combine_first(pub_tracker['Pre_OpenAlex_ID'])\n",
    "\n",
    "# Merge list-based columns\n",
    "pub_tracker['ListofAlexIds'] = pub_tracker.apply(\n",
    "    lambda row: row['ListofAlexIds'] if row['ListofAlexIds'] else row['Pre_ListofAlexIds'], axis=1)\n",
    "\n",
    "pub_tracker['ListofNames'] = pub_tracker.apply(\n",
    "    lambda row: row['ListofNames'] if row['ListofNames'] else row['Pre_ListofNames'], axis=1)\n",
    "\n",
    "pub_tracker['ListofOrcids'] = pub_tracker.apply(\n",
    "    lambda row: row['ListofOrcids'] if row['ListofOrcids'] else row['Pre_ListofOrcids'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ca26a",
   "metadata": {},
   "source": [
    "## Get openalex id for work and lists of names, open alex ids, and orcids for zenodo works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bcd7c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\1833475204.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'W4393681028' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  zenodo.at[idx, 'OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DOI 10.5281/zenodo.12690495: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12690495\n",
      "Error processing DOI 10.5281/zenodo.7153540: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7153540\n",
      "Error processing DOI 10.5281/zenodo.8204348: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.8204348\n",
      "Error processing DOI 10.5281/zenodo.8352764: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.8352764\n",
      "Error processing DOI 10.5281/zenodo.11244913: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11244913\n",
      "Error processing DOI 10.5281/zenodo.10896376: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896376\n",
      "Error processing DOI 10.5281/zenodo.11065259: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11065259\n",
      "Error processing DOI 10.5281/zenodo.4649457: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.4649457\n",
      "Error processing DOI 10.5281/zenodo.11077189: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11077189\n",
      "Error processing DOI 10.5281/zenodo.10928257: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10928257\n",
      "Error processing DOI 10.5281/zenodo.10162265: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10162265\n",
      "Error processing DOI 10.5281/zenodo.10850897: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10850897\n",
      "Error processing DOI 10.5281/zenodo.10819039: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10819039\n",
      "Error processing DOI 10.5281/zenodo.10056244: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10056244\n",
      "Error processing DOI 10.5281/zenodo.10798584: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10798584\n",
      "Error processing DOI 10.5281/zenodo.13332144: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13332144\n",
      "Error processing DOI 10.5281/zenodo.7153493: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7153493\n",
      "Error processing DOI 10.5281/zenodo.10819073: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10819073\n",
      "Error processing DOI 10.5281/zenodo.11153955: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11153955\n",
      "Error processing DOI 10.5281/zenodo.10896364: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896364\n",
      "Error processing DOI 10.5281/zenodo.8139563: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.8139563\n",
      "Error processing DOI 10.5281/zenodo.13381067: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13381067\n",
      "Error processing DOI 10.5281/zenodo.11519152: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11519152\n",
      "Error processing DOI 10.5281/zenodo.13251243: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13251243\n",
      "Error processing DOI 10.5281/zenodo.10714316: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10714316\n",
      "Error processing DOI 10.5281/zenodo.6539372: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6539372\n",
      "Error processing DOI 10.5281/zenodo.7346957: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7346957\n",
      "Error processing DOI 10.5281/zenodo.5854954: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.5854954\n",
      "Error processing DOI 10.5281/zenodo.10976403: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10976403\n",
      "Error processing DOI 10.5281/zenodo.13384532: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13384532\n",
      "Error processing DOI 10.5281/zenodo.13755496: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13755496\n",
      "Error processing DOI 10.5281/zenodo.13169485: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13169485\n",
      "Error processing DOI 10.5281/zenodo.10396372: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10396372\n",
      "Error processing DOI 10.5281/zenodo.10470982: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10470982\n",
      "Error processing DOI 10.5281/zenodo.10470795: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10470795\n",
      "Error processing DOI 10.5281/zenodo.10732697: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10732697\n",
      "Error processing DOI 10.5281/zenodo.11126860: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11126860\n",
      "Error processing DOI 10.5281/zenodo.13381181: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13381181\n",
      "Error processing DOI 10.5281/zenodo.7183678: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7183678\n",
      "Error processing DOI 10.5281/zenodo.13855996: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13855996\n",
      "Error processing DOI 10.5281/zenodo.11585274: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11585274\n",
      "Error processing DOI 10.5281/zenodo.12684329: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12684329\n",
      "Error processing DOI 10.5281/zenodo.12191805: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12191805\n",
      "Error processing DOI 10.5281/zenodo.10791354: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10791354\n",
      "Error processing DOI 10.5281/zenodo.6477921: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6477921\n",
      "Error processing DOI 10.5281/zenodo.10696967: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10696967\n",
      "Error processing DOI 10.5281/zenodo.10951333: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10951333\n",
      "Error processing DOI 10.5281/zenodo.10703094: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10703094\n",
      "Error processing DOI 10.5281/zenodo.6587708: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6587708\n",
      "Error processing DOI 10.5281/zenodo.12531178: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12531178\n",
      "Error processing DOI 10.5281/zenodo.11243617: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11243617\n",
      "Error processing DOI 10.5281/zenodo.11060950: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11060950\n",
      "Error processing DOI 10.5281/zenodo.11122117: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11122117\n",
      "Error processing DOI 10.5281/zenodo.13768680: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13768680\n",
      "Error processing DOI 10.5281/zenodo.13378407: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13378407\n",
      "Error processing DOI 10.5281/zenodo.11529071: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11529071\n",
      "Error processing DOI 10.5281/zenodo.7153508: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7153508\n",
      "Error processing DOI 10.5281/zenodo.10397773: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10397773\n",
      "Error processing DOI 10.5281/zenodo.13321153: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13321153\n",
      "Error processing DOI 10.5281/zenodo.10908572: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10908572\n",
      "Error processing DOI 10.5281/zenodo.10630752: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10630752\n",
      "Error processing DOI 10.5281/zenodo.6477900: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6477900\n",
      "Error processing DOI 10.5281/zenodo.8384710: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.8384710\n",
      "Error processing DOI 10.5281/zenodo.6475864: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6475864\n",
      "Error processing DOI 10.5281/zenodo.10896135: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896135\n",
      "Error processing DOI 10.5281/zenodo.10904059: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10904059\n",
      "Error processing DOI 10.5281/zenodo.13837652: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13837652\n",
      "Error processing DOI 10.5281/zenodo.10637353: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10637353\n",
      "Error processing DOI 10.5281/zenodo.11397910: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11397910\n",
      "Error processing DOI 10.5281/zenodo.10697254: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10697254\n",
      "Error processing DOI 10.5281/zenodo.7405544: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7405544\n",
      "Error processing DOI 10.5281/zenodo.7802755: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7802755\n",
      "Error processing DOI 10.5281/zenodo.7693103: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7693103\n",
      "Error processing DOI 10.5281/zenodo.10896142: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896142\n",
      "Error processing DOI 10.5281/zenodo.10644822: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10644822\n",
      "Error processing DOI 10.5281/zenodo.11262613: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11262613\n",
      "Error processing DOI 10.5281/zenodo.11189934: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11189934\n",
      "Error processing DOI 10.5281/zenodo.10776591: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10776591\n",
      "Error processing DOI 10.5281/zenodo.10072984: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10072984\n",
      "Error processing DOI 10.5281/zenodo.13897831: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13897831\n",
      "Error processing DOI 10.5281/zenodo.10896125: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896125\n",
      "Error processing DOI 10.5281/zenodo.10471496: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10471496\n",
      "Error processing DOI 10.5281/zenodo.13887806: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13887806\n",
      "Error processing DOI 10.5281/zenodo.13769802: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13769802\n",
      "Error processing DOI 10.5281/zenodo.13897878: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13897878\n",
      "Error processing DOI 10.5281/zenodo.13620762: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13620762\n",
      "Error processing DOI 10.5281/zenodo.10962119: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10962119\n",
      "Error processing DOI 10.5281/zenodo.4900679: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.4900679\n",
      "Error processing DOI 10.5281/zenodo.5525370: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.5525370\n",
      "Error processing DOI 10.5281/zenodo.7504034: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7504034\n",
      "Error processing DOI 10.5281/zenodo.10896130: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10896130\n",
      "Error processing DOI 10.5281/zenodo.10887655: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10887655\n",
      "Error processing DOI 10.5281/zenodo.10774734: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10774734\n",
      "Error processing DOI 10.5281/zenodo.11831299: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11831299\n",
      "Error processing DOI 10.5281/zenodo.10887623: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10887623\n",
      "Error processing DOI 10.5281/zenodo.10819194: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10819194\n",
      "Error processing DOI 10.5281/zenodo.10819065: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10819065\n",
      "Error processing DOI 10.5281/zenodo.10499027: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10499027\n",
      "Error processing DOI 10.5281/zenodo.13380404: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13380404\n",
      "Error processing DOI 10.5281/zenodo.10791411: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10791411\n",
      "Error processing DOI 10.5281/zenodo.7541954: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.7541954\n",
      "Error processing DOI 10.5281/zenodo.11118235: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11118235\n",
      "Error processing DOI 10.5281/zenodo.10850011: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10850011\n",
      "Error processing DOI 10.5281/zenodo.6607749: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6607749\n",
      "Error processing DOI 10.5281/zenodo.11176979: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11176979\n",
      "Error processing DOI 10.5281/zenodo.10908502: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10908502\n",
      "Error processing DOI 10.5281/zenodo.13381814: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13381814\n",
      "Error processing DOI 10.5281/zenodo.10956842: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10956842\n",
      "Error processing DOI 10.5281/zenodo.10150539: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10150539\n",
      "Error processing DOI 10.5281/zenodo.11518850: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11518850\n",
      "Error processing DOI 10.5281/zenodo.10397715: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10397715\n",
      "Error processing DOI 10.5281/zenodo.10606989: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10606989\n",
      "Error processing DOI 10.5281/zenodo.11065277: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11065277\n",
      "Error processing DOI 10.5281/zenodo.8015472: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.8015472\n",
      "Error processing DOI 10.5281/zenodo.6474033: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6474033\n",
      "Error processing DOI 10.5281/zenodo.10607238: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10607238\n",
      "Error processing DOI 10.5281/zenodo.10903566: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10903566\n",
      "Error processing DOI 10.5281/zenodo.10822458: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10822458\n",
      "Error processing DOI 10.5281/zenodo.12751640: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12751640\n",
      "Error processing DOI 10.5281/zenodo.13160664: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13160664\n",
      "Error processing DOI 10.5281/zenodo.10886973: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10886973\n",
      "Error processing DOI 10.5281/zenodo.10606795: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10606795\n",
      "Error processing DOI 10.5281/zenodo.12702249: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.12702249\n",
      "Error processing DOI 10.5281/zenodo.10578308: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10578308\n",
      "Error processing DOI 10.5281/zenodo.13249956: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13249956\n",
      "Error processing DOI 10.5281/zenodo.13946597: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13946597\n",
      "Error processing DOI 10.5281/zenodo.10044967: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10044967\n",
      "Error processing DOI 10.5281/zenodo.11099669: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.11099669\n",
      "Error processing DOI 10.5281/zenodo.13769766: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13769766\n",
      "Error processing DOI 10.5281/zenodo.10475643: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10475643\n",
      "Error processing DOI 10.5281/zenodo.6374061: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6374061\n",
      "Error processing DOI 10.5281/zenodo.13969544: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13969544\n",
      "Error processing DOI 10.5281/zenodo.10062179: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10062179\n",
      "Error processing DOI 10.5281/zenodo.13379191: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.13379191\n",
      "Error processing DOI 10.5281/zenodo.10797936: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10797936\n",
      "Error processing DOI 10.5281/zenodo.10600748: 404 Client Error: Not Found for url: https://api.openalex.org/works/https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.10600748\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize your new columns\n",
    "zenodo['OpenAlex_ID'] = np.nan\n",
    "zenodo['ListofAlexIds'] = [[] for _ in range(len(zenodo))]\n",
    "zenodo['ListofNames'] = [[] for _ in range(len(zenodo))]\n",
    "zenodo['ListofOrcids'] = [[] for _ in range(len(zenodo))]\n",
    "\n",
    "# Iterate through the DOIs\n",
    "for idx, row in zenodo.iterrows():\n",
    "    doi_suffix = row['pids.doi.identifier']\n",
    "    if pd.notna(doi_suffix):\n",
    "        try:\n",
    "            doi_url = f\"https://doi.org/{doi_suffix}\"\n",
    "            work_json = Works()[doi_url]\n",
    "\n",
    "            # Extract OpenAlex ID\n",
    "            work_id = work_json.get('id', '')\n",
    "            if work_id.startswith(\"https://openalex.org/\"):\n",
    "                zenodo.at[idx, 'OpenAlex_ID'] = work_id.replace(\"https://openalex.org/\", \"\")\n",
    "\n",
    "            # Extract authorship information\n",
    "            alex_ids = []\n",
    "            names = []\n",
    "            orcids = []\n",
    "\n",
    "            for author_info in work_json.get('authorships', []):\n",
    "                author = author_info.get('author', {})\n",
    "\n",
    "                # Extract and clean author ID\n",
    "                author_id = author.get('id', '')\n",
    "                if author_id.startswith(\"https://openalex.org/\"):\n",
    "                    alex_ids.append(author_id.replace(\"https://openalex.org/\", \"\"))\n",
    "                else:\n",
    "                    alex_ids.append(None)\n",
    "\n",
    "                # Extract name\n",
    "                names.append(author.get('display_name', None))\n",
    "\n",
    "                # Extract and clean ORCID\n",
    "                orcid = author.get('orcid', '')\n",
    "                if orcid and orcid.startswith(\"https://orcid.org/\"):\n",
    "                    orcids.append(orcid.replace(\"https://orcid.org/\", \"\"))\n",
    "                else:\n",
    "                    orcids.append(None)\n",
    "\n",
    "            zenodo.at[idx, 'ListofAlexIds'] = alex_ids\n",
    "            zenodo.at[idx, 'ListofNames'] = names\n",
    "            zenodo.at[idx, 'ListofOrcids'] = orcids\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOI {doi_suffix}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517436d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo.to_excel('zenodo_df.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e59d0",
   "metadata": {},
   "source": [
    "#### save pub_tracker and zenodo tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "752920b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'team', 'doi_pre', 'doi_pub', 'date_added_preprint',\n",
       "       'date_added_publication', 'source_preprint', 'source_publication',\n",
       "       'original', 'notes', 'Preprint in SF tracker',\n",
       "       'publication in SF tracker', 'apc_amount', 'apc_status', 'OpenAlex_ID',\n",
       "       'ListofAlexIds', 'ListofNames', 'ListofOrcids', 'Pre_OpenAlex_ID',\n",
       "       'Pre_ListofAlexIds', 'Pre_ListofNames', 'Pre_ListofOrcids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_tracker.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb868d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_tracker.drop(columns=['ListofAlexIds', 'ListofNames', 'ListofOrcids', 'Pre_OpenAlex_ID',\n",
    "       'Pre_ListofAlexIds', 'Pre_ListofNames', 'Pre_ListofOrcids'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c78a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_tracker.to_csv(\"publication_tracker.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46bd9d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created', 'pids.doi.identifier', 'metadata.title',\n",
       "       'metadata.description', 'metadata.resource_type.title.en',\n",
       "       'metadata.publication_date', 'metadata.creators.person_or_org.type',\n",
       "       'metadata.creators.person_or_org.name', 'metadata.rights.id',\n",
       "       'OpenAlex_ID', 'ListofAlexIds', 'ListofNames', 'ListofOrcids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zenodo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "469d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo.drop(columns=['ListofAlexIds', 'ListofNames', 'ListofOrcids'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c1846c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo.to_csv(\"zenodo_tracker.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb66285",
   "metadata": {},
   "source": [
    "## Create new df that maps people frmo roster to people in publications and zenodo works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d35cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\school\\AppData\\Local\\Temp\\ipykernel_80552\\3239494278.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(len).nunique(axis=1) == 1).all(), \"List lengths are not equal in some rows!\"\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "for col in ['ListofAlexIds', 'ListofNames', 'ListofOrcids']:\n",
    "        pub_tracker[col] = pub_tracker[col].apply(\n",
    "                lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    "        )\n",
    "# Ensure all list columns have the same length per row\n",
    "assert (pub_tracker[['ListofAlexIds', 'ListofNames', 'ListofOrcids']]\n",
    "        .applymap(len).nunique(axis=1) == 1).all(), \"List lengths are not equal in some rows!\"\n",
    "\n",
    "# Explode all 3 columns together while maintaining alignment\n",
    "exploded_pub_tracker = pub_tracker.explode(['ListofAlexIds', 'ListofNames', 'ListofOrcids'], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all list columns have the same length per row\n",
    "assert (zenodo[['ListofAlexIds', 'ListofNames', 'ListofOrcids']]\n",
    "        .applymap(len).nunique(axis=1) == 1).all(), \"List lengths are not equal in some rows!\"\n",
    "\n",
    "# Explode all 3 columns together while maintaining alignment\n",
    "exploded_zenodo = zenodo.explode(['ListofAlexIds', 'ListofNames', 'ListofOrcids'], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a65c0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_teams = pd.read_csv(\"final_team_roster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_middle_names(full_name):\n",
    "    # Split the name into parts\n",
    "    full_name = str(full_name)  # Ensure it's a string\n",
    "    parts = full_name.strip().split()\n",
    "    if len(parts) <= 2:\n",
    "        return full_name  # No middle name to remove\n",
    "    return f\"{parts[0]} {parts[-1]}\"  # Keep only first and last\n",
    "\n",
    "# Apply this to the ListofNames column\n",
    "exploded_pub_tracker['ListofNames'] = exploded_pub_tracker['ListofNames'].apply(remove_middle_names)\n",
    "\n",
    "# Preview the cleaned names\n",
    "#print(exploded_pub_tracker['ListofNames'].head())\n",
    "\n",
    "# Apply this to the ListofNames column\n",
    "exploded_zenodo['ListofNames'] = exploded_zenodo['ListofNames'].apply(remove_middle_names)\n",
    "\n",
    "# Preview the cleaned names\n",
    "#print(exploded_zenodo['ListofNames'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eee9e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine First Name and Last Name, strip any extra spaces\n",
    "combined_teams[\"Full Name\"] = (\n",
    "    combined_teams[\"First Name\"].fillna(\"\").str.strip() + \" \" +\n",
    "    combined_teams[\"Last Name\"].fillna(\"\").str.strip()\n",
    ").str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ffde929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert strings that look like lists into actual lists\n",
    "exploded_pub_tracker[\"ListofAlexIds\"] = exploded_pub_tracker[\"ListofAlexIds\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c90a711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert strings that look like lists into actual lists\n",
    "exploded_zenodo[\"ListofAlexIds\"] = exploded_zenodo[\"ListofAlexIds\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544e038",
   "metadata": {},
   "source": [
    "### Add Role and Team info to tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4074547",
   "metadata": {},
   "source": [
    "### drop columns from exploded_pub_tracker and exploded zenodo_tracker to create tables for mapping people to publications and zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18f37e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'team', 'doi_pre', 'doi_pub', 'date_added_preprint',\n",
       "       'date_added_publication', 'source_preprint', 'source_publication',\n",
       "       'original', 'notes', 'Preprint in SF tracker',\n",
       "       'publication in SF tracker', 'apc_amount', 'apc_status', 'OpenAlex_ID',\n",
       "       'ListofAlexIds', 'ListofNames', 'ListofOrcids', 'Pre_OpenAlex_ID',\n",
       "       'Pre_ListofAlexIds', 'Pre_ListofNames', 'Pre_ListofOrcids',\n",
       "       'AlexID_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_pub_tracker.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d74239",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_pub_tracker.drop(columns=['Title', 'team', 'doi_pre', 'doi_pub', 'date_added_preprint',\n",
    "       'date_added_publication', 'source_preprint', 'source_publication',\n",
    "       'original', 'notes', 'Preprint in SF tracker',\n",
    "       'publication in SF tracker', 'apc_amount', 'apc_status', 'Pre_OpenAlex_ID',\n",
    "       'Pre_ListofAlexIds', 'Pre_ListofNames', 'Pre_ListofOrcids',\n",
    "       'AlexID_match'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83b41cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_pub_tracker.rename(columns={'OpenAlex_ID': 'WorkOpenAlex_ID', 'ListofAlexIds': 'PersonOpenAlex_ID', 'ListofNames': 'PersonName', 'ListofOrcids': 'PersonOrcid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c11bb63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created', 'pids.doi.identifier', 'metadata.title',\n",
       "       'metadata.description', 'metadata.resource_type.title.en',\n",
       "       'metadata.publication_date', 'metadata.creators.person_or_org.type',\n",
       "       'metadata.creators.person_or_org.name', 'metadata.rights.id',\n",
       "       'OpenAlex_ID', 'ListofAlexIds', 'ListofNames', 'ListofOrcids',\n",
       "       'AlexID_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_zenodo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f05ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_zenodo.drop(columns=['id', 'created', 'pids.doi.identifier', 'metadata.title',\n",
    "       'metadata.description', 'metadata.resource_type.title.en',\n",
    "       'metadata.publication_date', 'metadata.creators.person_or_org.type',\n",
    "       'metadata.creators.person_or_org.name', 'metadata.rights.id',\n",
    "       'AlexID_match'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee198c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_zenodo.rename(columns={'OpenAlex_ID': 'ZenodoOpenAlex_ID', 'ListofAlexIds': 'PersonOpenAlex_ID', 'ListofNames': 'PersonName', 'ListofOrcids': 'PersonOrcid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99725ed",
   "metadata": {},
   "source": [
    "## Add Role and Team info to pub_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6d4acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Split pub_df into two: one with valid ListofAlexIds, one without\n",
    "valid_ids = exploded_pub_tracker[exploded_pub_tracker['PersonOpenAlex_ID'].notna() & (exploded_pub_tracker['PersonOpenAlex_ID'] != \"\")]\n",
    "missing_ids = exploded_pub_tracker[exploded_pub_tracker['PersonOpenAlex_ID'].isna() | (exploded_pub_tracker['PersonOpenAlex_ID'] == \"\")]\n",
    "\n",
    "# Merge only the valid part\n",
    "merged_valid = valid_ids.merge(\n",
    "    combined_teams[['AllOpenAlex_ID', 'Role', 'Team']],\n",
    "    left_on='PersonOpenAlex_ID',\n",
    "    right_on='AllOpenAlex_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the now-redundant join column\n",
    "merged_valid.drop(columns=['AllOpenAlex_ID'], inplace=True)\n",
    "\n",
    "# For missing IDs, fill Role and Team with NaN explicitly\n",
    "missing_ids = missing_ids.copy()\n",
    "missing_ids['Role'] = np.nan\n",
    "missing_ids['Team'] = np.nan\n",
    "\n",
    "# Concatenate the cleaned frames back together\n",
    "pub_df = pd.concat([merged_valid, missing_ids], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0734e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_middle_name(full_name):\n",
    "    if pd.notna(full_name) and isinstance(full_name, str):\n",
    "        parts = full_name.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[0]} {parts[-1]}\"  # Keep only first and last name\n",
    "        return parts[0]  # If there's only one part, return as is\n",
    "    return None\n",
    "\n",
    "# Apply to the PersonName column\n",
    "pub_df[\"FirstLastName\"] = pub_df[\"PersonName\"].apply(remove_middle_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d79107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map team from pub_tracker to pub_df based on matching OpenAlex_ID and WorkOpenAlex_ID\n",
    "pub_df = pub_df.merge(\n",
    "    pub_tracker[['OpenAlex_ID', 'team']],\n",
    "    left_on='WorkOpenAlex_ID',\n",
    "    right_on='OpenAlex_ID',\n",
    "    how='left',\n",
    "    suffixes=('', '_from_tracker')\n",
    ")\n",
    "\n",
    "# If pub_df already has a 'team' column, update only where it's missing\n",
    "if 'team_x' in pub_df.columns and 'team_y' in pub_df.columns:\n",
    "    pub_df['team'] = pub_df['team_x'].combine_first(pub_df['team_y'])\n",
    "    pub_df.drop(['team_x', 'team_y'], axis=1, inplace=True)\n",
    "elif 'team_y' in pub_df.columns:\n",
    "    pub_df['team'] = pub_df['team_y']\n",
    "    pub_df.drop(['team_y'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the extra OpenAlex_ID column from merge\n",
    "if 'OpenAlex_ID' in pub_df.columns:\n",
    "    pub_df.drop(['OpenAlex_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79d561f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Only process rows in pub_df where Role is blank\n",
    "pub_df_to_update = pub_df[pub_df['Role'].isna()].copy()\n",
    "\n",
    "# Standardize combined_teams for matching\n",
    "combined_teams['FullName'] = combined_teams['First Name'].str.strip() + ' ' + combined_teams['Last Name'].str.strip()\n",
    "combined_teams['StrippedTeam'] = combined_teams['Team'].str.replace('Team ', '', regex=False).str.strip()\n",
    "\n",
    "# Loop through the rows to perform rough match and update\n",
    "for idx, row in pub_df_to_update.iterrows():\n",
    "    name = row['FirstLastName']\n",
    "    team = str(row['team']).strip()\n",
    "\n",
    "    match = combined_teams[(combined_teams['FullName'] == name) & \n",
    "                         (combined_teams['StrippedTeam'] == team)]\n",
    "\n",
    "    if not match.empty:\n",
    "        matched_row = match.iloc[0]  # Use the first match found\n",
    "        pub_df.at[idx, 'Role'] = matched_row['Role']\n",
    "        pub_df.at[idx, 'Team'] = matched_row['Team']  # This will be the full 'Team AAA' style\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6318fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df[\"PersonName\"] = pub_df[\"FirstLastName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ecd0aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df.drop(columns=['FirstLastName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db950957",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df.drop(columns=['team'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b51b7",
   "metadata": {},
   "source": [
    "## Add people in teams not on works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bdaaa108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparable columns in both dataframes\n",
    "combined_teams['PersonName'] = combined_teams['First Name'].str.strip() + ' ' + combined_teams['Last Name'].str.strip()\n",
    "\n",
    "# Select the relevant columns from both dataframes\n",
    "pub_keys = pub_df[['PersonName', 'Role', 'Team']].dropna()\n",
    "personnel_keys = combined_teams[['PersonName', 'Role', 'Team']].dropna()\n",
    "\n",
    "# Perform anti-join: find rows in combined_teams that are not in pub_df\n",
    "merged = personnel_keys.merge(pub_keys.drop_duplicates(), \n",
    "                               on=['PersonName', 'Role', 'Team'], \n",
    "                               how='left', indicator=True)\n",
    "\n",
    "# Only rows not found in pub_df\n",
    "missing_rows = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "# Get corresponding full rows from combined_teams\n",
    "rows_to_add = combined_teams.merge(missing_rows, \n",
    "                                 on=['PersonName', 'Role', 'Team'], \n",
    "                                 how='inner')\n",
    "\n",
    "# Select and rename the columns to match pub_df format\n",
    "rows_to_add = rows_to_add[['PersonName', 'Role', 'Team']]\n",
    "rows_to_add['team'] = rows_to_add['Team'].str.replace('Team ', '', regex=False)  # create lowercase version\n",
    "\n",
    "# Append to pub_df\n",
    "pub_df = pd.concat([pub_df, rows_to_add], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e65affc",
   "metadata": {},
   "source": [
    "## Locate OpenAlex ID for rows in publication people tracker missing Alex Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ef7a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure matching keys are aligned\n",
    "combined_teams['PersonName'] = combined_teams['First Name'].str.strip() + ' ' + combined_teams['Last Name'].str.strip()\n",
    "combined_teams['Team_clean'] = combined_teams['Team']\n",
    "\n",
    "# Loop through rows where PersonOpenAlex_ID is missing\n",
    "for idx, row in pub_df[pub_df['PersonOpenAlex_ID'].isna()].iterrows():\n",
    "    first_last = row['PersonName']\n",
    "    team_clean = str(row['Team']).strip()  # Safely convert to string and strip\n",
    "\n",
    "    match = combined_teams[\n",
    "        (combined_teams['PersonName'] == first_last) &\n",
    "        (combined_teams['Team_clean'] == team_clean)\n",
    "    ]\n",
    "\n",
    "    if not match.empty:\n",
    "        pub_df.at[idx, 'PersonOpenAlex_ID'] = match.iloc[0]['AllOpenAlex_ID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219b67c",
   "metadata": {},
   "source": [
    "## Add corresponding author (yes/no) column to people to publication mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5df196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temp column in pub_tracker for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "142d73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add corresponding_authors column to pub_tracker\n",
    "pub_tracker['corresponding_authors'] = pub_tracker['OpenAlex_ID'].apply(\n",
    "    lambda openalex_id: Works()[f\"https://openalex.org/{openalex_id}\"].get(\"corresponding_author_ids\", []) if pd.notna(openalex_id) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf7448e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'https://openalex.org/' from each item in the corresponding_authors list for every row\n",
    "pub_tracker['corresponding_authors'] = pub_tracker['corresponding_authors'].apply(\n",
    "    lambda lst: [x.replace('https://openalex.org/', '') if isinstance(x, str) else x for x in lst]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eeee330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from OpenAlex_ID to corresponding_authors list\n",
    "corresponding_authors_map = pub_tracker.set_index('OpenAlex_ID')['corresponding_authors'].to_dict()\n",
    "\n",
    "def is_corresponding_author(row):\n",
    "    work_id = row['WorkOpenAlex_ID']\n",
    "    person_id = row['PersonOpenAlex_ID']\n",
    "    if pd.notna(work_id) and pd.notna(person_id):\n",
    "        authors_list = corresponding_authors_map.get(work_id, [])\n",
    "        return \"Yes\" if person_id in authors_list else \"No\"\n",
    "    return \"No\"\n",
    "\n",
    "pub_df['IsCorrespondingAuthor'] = pub_df.apply(is_corresponding_author, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3664a761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>team</th>\n",
       "      <th>doi_pre</th>\n",
       "      <th>doi_pub</th>\n",
       "      <th>date_added_preprint</th>\n",
       "      <th>date_added_publication</th>\n",
       "      <th>source_preprint</th>\n",
       "      <th>source_publication</th>\n",
       "      <th>original</th>\n",
       "      <th>notes</th>\n",
       "      <th>Preprint in SF tracker</th>\n",
       "      <th>publication in SF tracker</th>\n",
       "      <th>apc_amount</th>\n",
       "      <th>apc_status</th>\n",
       "      <th>OpenAlex_ID</th>\n",
       "      <th>corresponding_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three-step docking by WIPI2, ATG16L1 and ATG3 ...</td>\n",
       "      <td>Hurley</td>\n",
       "      <td>10.1101/2023.07.17.549391</td>\n",
       "      <td>10.1126/sciadv.adj8027</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>2024-02-07 00:00:00</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>other(email to DS)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>W4391629214</td>\n",
       "      <td>[A5061877082, A5061450716, A5059945365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-ancestry genome-wide meta-analysis in Pa...</td>\n",
       "      <td>GP2</td>\n",
       "      <td>10.1101/2022.08.04.22278432</td>\n",
       "      <td>10.1038/s41588-023-01584-8</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>2024-02-07 00:00:00</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>other(gp2_blog)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4390345401</td>\n",
       "      <td>[A5031512056]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fluorescence Microscopy Shadow Imaging for Neu...</td>\n",
       "      <td>Vila</td>\n",
       "      <td>review</td>\n",
       "      <td>10.3389/fncel.2024.1330100</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>2024-02-07 00:00:00</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>hub</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>W4391841711</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D Bioprinting of Human Neural Tissues with Fu...</td>\n",
       "      <td>Scherzer</td>\n",
       "      <td>10.1101/2024.01.18.576289</td>\n",
       "      <td>10.1016/j.stem.2023.12.009</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>2024-02-09 00:00:00</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>google_alert</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4391450102</td>\n",
       "      <td>[A5101605513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comprehensive structural variant detection: Fr...</td>\n",
       "      <td>Voet</td>\n",
       "      <td>10.1101/2022.04.04.487055</td>\n",
       "      <td>10.1038/s41587-023-02024-y</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>2024-02-09 00:00:00</td>\n",
       "      <td>before_doi_tracker</td>\n",
       "      <td>hub</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4390500910</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Current safety recommendations for handling mo...</td>\n",
       "      <td>Volpicelli-Daley</td>\n",
       "      <td>does_not_exist</td>\n",
       "      <td>10.1016/j.nbd.2025.106820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lens</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4407000621</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Aging, cellular senescence and Parkinson's dis...</td>\n",
       "      <td>Lee</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>10.1177/1877718X251316552</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>2025-06-06 00:00:00</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>lens</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4407112723</td>\n",
       "      <td>[A5037205059]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Targeting mitophagy in neurodegenerative diseases</td>\n",
       "      <td>Alessi</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>10.1038/s41573-024-01105-0</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>2025-06-06 00:00:00</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>lens</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4406342572</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>How Membrane Contact Sites Shape the Phagophore</td>\n",
       "      <td>Harper</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>10.1177/25152564231162495</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>2025-06-06 00:00:00</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>lens</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4376459430</td>\n",
       "      <td>[A5006303094]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Prospects for Disease Slowing in Parkinson Dis...</td>\n",
       "      <td>Schapira</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>10.1146/annurev-pharmtox-022124-033653</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>2025-06-12 00:00:00</td>\n",
       "      <td>NA_review</td>\n",
       "      <td>lens</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W4401206190</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title              team  \\\n",
       "0    Three-step docking by WIPI2, ATG16L1 and ATG3 ...            Hurley   \n",
       "1    Multi-ancestry genome-wide meta-analysis in Pa...               GP2   \n",
       "2    Fluorescence Microscopy Shadow Imaging for Neu...              Vila   \n",
       "3    3D Bioprinting of Human Neural Tissues with Fu...          Scherzer   \n",
       "4    Comprehensive structural variant detection: Fr...              Voet   \n",
       "..                                                 ...               ...   \n",
       "558  Current safety recommendations for handling mo...  Volpicelli-Daley   \n",
       "559  Aging, cellular senescence and Parkinson's dis...               Lee   \n",
       "560  Targeting mitophagy in neurodegenerative diseases            Alessi   \n",
       "561    How Membrane Contact Sites Shape the Phagophore            Harper   \n",
       "562  Prospects for Disease Slowing in Parkinson Dis...          Schapira   \n",
       "\n",
       "                         doi_pre                                 doi_pub  \\\n",
       "0      10.1101/2023.07.17.549391                  10.1126/sciadv.adj8027   \n",
       "1    10.1101/2022.08.04.22278432              10.1038/s41588-023-01584-8   \n",
       "2                         review              10.3389/fncel.2024.1330100   \n",
       "3      10.1101/2024.01.18.576289              10.1016/j.stem.2023.12.009   \n",
       "4      10.1101/2022.04.04.487055              10.1038/s41587-023-02024-y   \n",
       "..                           ...                                     ...   \n",
       "558               does_not_exist               10.1016/j.nbd.2025.106820   \n",
       "559                    NA_review               10.1177/1877718X251316552   \n",
       "560                    NA_review              10.1038/s41573-024-01105-0   \n",
       "561                    NA_review               10.1177/25152564231162495   \n",
       "562                    NA_review  10.1146/annurev-pharmtox-022124-033653   \n",
       "\n",
       "    date_added_preprint date_added_publication     source_preprint  \\\n",
       "0    before_doi_tracker    2024-02-07 00:00:00  before_doi_tracker   \n",
       "1    before_doi_tracker    2024-02-07 00:00:00  before_doi_tracker   \n",
       "2             NA_review    2024-02-07 00:00:00           NA_review   \n",
       "3    before_doi_tracker    2024-02-09 00:00:00  before_doi_tracker   \n",
       "4    before_doi_tracker    2024-02-09 00:00:00  before_doi_tracker   \n",
       "..                  ...                    ...                 ...   \n",
       "558                 NaN    2025-06-05 00:00:00                 NaN   \n",
       "559           NA_review    2025-06-06 00:00:00           NA_review   \n",
       "560           NA_review    2025-06-06 00:00:00           NA_review   \n",
       "561           NA_review    2025-06-06 00:00:00           NA_review   \n",
       "562           NA_review    2025-06-12 00:00:00           NA_review   \n",
       "\n",
       "     source_publication  original notes  Preprint in SF tracker  \\\n",
       "0    other(email to DS)         1   NaN                     1.0   \n",
       "1       other(gp2_blog)         1   NaN                     1.0   \n",
       "2                   hub         0   NaN                     NaN   \n",
       "3          google_alert         1   NaN                     1.0   \n",
       "4                   hub         1   NaN                     1.0   \n",
       "..                  ...       ...   ...                     ...   \n",
       "558                lens         0   NaN                     NaN   \n",
       "559                lens         0   NaN                     NaN   \n",
       "560                lens         0   NaN                     NaN   \n",
       "561                lens         0   NaN                     NaN   \n",
       "562                lens         0   NaN                     NaN   \n",
       "\n",
       "    publication in SF tracker  apc_amount apc_status  OpenAlex_ID  \\\n",
       "0                           1      4500.0       Paid  W4391629214   \n",
       "1                           1         NaN        NaN  W4390345401   \n",
       "2                         NaN      3295.0       Paid  W4391841711   \n",
       "3                           1         NaN        NaN  W4391450102   \n",
       "4                           1         NaN        NaN  W4390500910   \n",
       "..                        ...         ...        ...          ...   \n",
       "558                         1         NaN        NaN  W4407000621   \n",
       "559                         1         NaN        NaN  W4407112723   \n",
       "560                         1         NaN        NaN  W4406342572   \n",
       "561                         1         NaN        NaN  W4376459430   \n",
       "562                         1         NaN        NaN  W4401206190   \n",
       "\n",
       "                       corresponding_authors  \n",
       "0    [A5061877082, A5061450716, A5059945365]  \n",
       "1                              [A5031512056]  \n",
       "2                                         []  \n",
       "3                              [A5101605513]  \n",
       "4                                         []  \n",
       "..                                       ...  \n",
       "558                                       []  \n",
       "559                            [A5037205059]  \n",
       "560                                       []  \n",
       "561                            [A5006303094]  \n",
       "562                                       []  \n",
       "\n",
       "[563 rows x 16 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94120f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkOpenAlex_ID</th>\n",
       "      <th>PersonOpenAlex_ID</th>\n",
       "      <th>PersonName</th>\n",
       "      <th>PersonOrcid</th>\n",
       "      <th>Role</th>\n",
       "      <th>Team</th>\n",
       "      <th>IsCorrespondingAuthor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W4391629214</td>\n",
       "      <td>A5028861095</td>\n",
       "      <td>Shanlin Rao</td>\n",
       "      <td>0000-0003-4892-5523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W4391629214</td>\n",
       "      <td>A5071900726</td>\n",
       "      <td>Lisa Strong</td>\n",
       "      <td>0000-0002-4293-8131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W4391629214</td>\n",
       "      <td>A5041244181</td>\n",
       "      <td>Xuefeng Ren</td>\n",
       "      <td>0000-0002-4822-4316</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Hurley</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W4391629214</td>\n",
       "      <td>A5033276727</td>\n",
       "      <td>Marvin Skulsuppaisarn</td>\n",
       "      <td>0000-0003-4041-7014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W4391629214</td>\n",
       "      <td>A5061877082</td>\n",
       "      <td>Michael Lazarou</td>\n",
       "      <td>0000-0003-2150-5545</td>\n",
       "      <td>Co-PI</td>\n",
       "      <td>Hurley</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A5102819545</td>\n",
       "      <td>Hannah Clarke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Wood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A5008450447</td>\n",
       "      <td>Rebeka Popovic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Wood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joe Robin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Wood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A5082240217</td>\n",
       "      <td>Alexandre Almeida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Wood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7069</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nika Vinkovic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Key Personnel</td>\n",
       "      <td>Wood</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7070 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WorkOpenAlex_ID PersonOpenAlex_ID             PersonName  \\\n",
       "0        W4391629214       A5028861095            Shanlin Rao   \n",
       "1        W4391629214       A5071900726            Lisa Strong   \n",
       "2        W4391629214       A5041244181            Xuefeng Ren   \n",
       "3        W4391629214       A5033276727  Marvin Skulsuppaisarn   \n",
       "4        W4391629214       A5061877082        Michael Lazarou   \n",
       "...              ...               ...                    ...   \n",
       "7065             NaN       A5102819545          Hannah Clarke   \n",
       "7066             NaN       A5008450447         Rebeka Popovic   \n",
       "7067             NaN               NaN              Joe Robin   \n",
       "7068             NaN       A5082240217      Alexandre Almeida   \n",
       "7069             NaN               NaN          Nika Vinkovic   \n",
       "\n",
       "              PersonOrcid           Role    Team IsCorrespondingAuthor  \n",
       "0     0000-0003-4892-5523            NaN     NaN                    No  \n",
       "1     0000-0002-4293-8131            NaN     NaN                    No  \n",
       "2     0000-0002-4822-4316  Key Personnel  Hurley                    No  \n",
       "3     0000-0003-4041-7014            NaN     NaN                    No  \n",
       "4     0000-0003-2150-5545          Co-PI  Hurley                   Yes  \n",
       "...                   ...            ...     ...                   ...  \n",
       "7065                  NaN  Key Personnel    Wood                    No  \n",
       "7066                  NaN  Key Personnel    Wood                    No  \n",
       "7067                  NaN  Key Personnel    Wood                    No  \n",
       "7068                  NaN  Key Personnel    Wood                    No  \n",
       "7069                  NaN  Key Personnel    Wood                    No  \n",
       "\n",
       "[7070 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da66d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df.drop(columns=['team'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0933b",
   "metadata": {},
   "source": [
    "## Save tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "227c00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_df.to_csv('people_to_publication_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6b240ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_zenodo.to_csv('people_to_zenodo_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e5c00",
   "metadata": {},
   "source": [
    "## Citation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50be2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_tracker = pd.read_csv(\"publication_tracker.csv\")\n",
    "pub_people = pd.read_csv(\"people_to_publication_mapping.csv\")\n",
    "combined_teams = pd.read_csv(\"final_team_roster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a68743",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pub_tracker.merge(pub_people[['WorkOpenAlex_ID', 'PersonOpenAlex_ID', 'PersonName',\n",
    "       'PersonOrcid', 'Role', 'Team', 'IsCorrespondingAuthor']],\n",
    "       left_on='OpenAlex_ID',\n",
    "       right_on='WorkOpenAlex_ID',\n",
    "       how = 'left').drop(columns=['WorkOpenAlex_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83ed283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'team', 'doi_pre', 'doi_pub', 'date_added_preprint',\n",
       "       'date_added_publication', 'source_preprint', 'source_publication',\n",
       "       'original', 'notes', 'Preprint in SF tracker',\n",
       "       'publication in SF tracker', 'apc_amount', 'apc_status', 'OpenAlex_ID',\n",
       "       'PersonOpenAlex_ID', 'PersonName', 'PersonOrcid', 'Role', 'Team',\n",
       "       'IsCorrespondingAuthor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that stayed the same (used for grouping)\n",
    "group_cols = ['Title', 'team', 'doi_pre', 'doi_pub', 'date_added_preprint',\n",
    "       'date_added_publication', 'source_preprint', 'source_publication',\n",
    "       'original', 'notes', 'Preprint in SF tracker',\n",
    "       'publication in SF tracker', 'apc_amount', 'apc_status', 'OpenAlex_ID']\n",
    "\n",
    "# Columns that were unlisted (you want to re-list them)\n",
    "list_cols = ['PersonOpenAlex_ID', 'PersonName', 'PersonOrcid', 'Role', 'Team',\n",
    "       'IsCorrespondingAuthor']\n",
    "\n",
    "# Sort the DataFrame to preserve original order before grouping\n",
    "df_sorted = network_df.sort_values(by=group_cols).copy()\n",
    "\n",
    "# Group and aggregate the list columns into lists\n",
    "aggregated_df = df_sorted.groupby(group_cols, as_index=False).agg({\n",
    "    col: lambda x: list(x) for col in list_cols\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba2f3cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f905736",
   "metadata": {},
   "source": [
    "column with list of references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fce475c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_get_referenced(openalex_id):\n",
    "    # handle NaN / empty\n",
    "    if not openalex_id or (isinstance(openalex_id, float) and pd.isna(openalex_id)):\n",
    "        return []\n",
    "    openalex_id = str(openalex_id).strip()\n",
    "    # strip full URL if present\n",
    "    if openalex_id.startswith(\"https://openalex.org/\"):\n",
    "        openalex_id = openalex_id.replace(\"https://openalex.org/\", \"\")\n",
    "    try:\n",
    "        work = Works()[openalex_id]\n",
    "        return work.get(\"referenced_works\", []) or []\n",
    "    except Exception:\n",
    "        # return empty list on any fetch error (404, rate limit, etc.)\n",
    "        return []\n",
    "\n",
    "network_df[\"ReferencedWorks\"] = network_df[\"OpenAlex_ID\"].apply(_safe_get_referenced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dbb4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df[\"ReferencedWorks\"] = network_df[\"ReferencedWorks\"].apply(\n",
    "    lambda lst: [item.replace(\"https://openalex.org/\", \"\") if isinstance(item, str) else item for item in lst]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac2d09",
   "metadata": {},
   "source": [
    "column for number of references from asap network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5521a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all OpenAlex_IDs for fast lookup\n",
    "openalex_id_set = set(network_df[\"OpenAlex_ID\"])\n",
    "\n",
    "# Count how many referenced works are also in OpenAlex_ID\n",
    "network_df[\"NumInternalReferences\"] = network_df[\"ReferencedWorks\"].apply(\n",
    "    lambda refs: sum(ref in openalex_id_set for ref in refs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6d717",
   "metadata": {},
   "source": [
    "column for num times each work has been cited by other works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "238d1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_get_cited_by_count(openalex_id):\n",
    "    # handle missing/NaN/empty\n",
    "    if not openalex_id or (isinstance(openalex_id, float) and pd.isna(openalex_id)):\n",
    "        return 0\n",
    "    openalex_id = str(openalex_id).strip()\n",
    "    # strip full URL if present\n",
    "    if openalex_id.startswith(\"https://openalex.org/\"):\n",
    "        openalex_id = openalex_id.replace(\"https://openalex.org/\", \"\")\n",
    "    try:\n",
    "        work = Works()[openalex_id]\n",
    "        return work.get(\"cited_by_count\", 0) if work else 0\n",
    "    except Exception:\n",
    "        # On any fetch error (404, rate limit, etc.) return 0\n",
    "        return 0\n",
    "\n",
    "network_df[\"CitedByCount\"] = network_df[\"OpenAlex_ID\"].apply(_safe_get_cited_by_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027d56d",
   "metadata": {},
   "source": [
    "column for num times each work has been cited by works in the asap network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b51e9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# For each row, count how many times its OpenAlex_ID appears in all ReferencedWorks lists\n",
    "\n",
    "# Flatten all ReferencedWorks into a single list\n",
    "all_referenced_ids = [ref for refs in network_df[\"ReferencedWorks\"] for ref in refs]\n",
    "referenced_counter = Counter(all_referenced_ids)\n",
    "\n",
    "# Map each OpenAlex_ID to its count in referenced_counter\n",
    "network_df[\"CitedByInternal\"] = network_df[\"OpenAlex_ID\"].map(lambda x: referenced_counter.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1c382f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Step 1: Custom parser for stringified lists that contain nan\n",
    "def parse_team(val):\n",
    "    if isinstance(val, list):  # Already parsed\n",
    "        return val\n",
    "    if pd.isna(val):  # True NaN\n",
    "        return []\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        # Replace bare `nan` (not quoted) with 'None' so ast.literal_eval won't crash\n",
    "        val_cleaned = re.sub(r'\\bnan\\b', 'None', val)\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val_cleaned)\n",
    "            if isinstance(parsed, list):\n",
    "                return parsed\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [val] if pd.notna(val) else []\n",
    "\n",
    "# Step 2: Remove real NaNs and deduplicate\n",
    "def clean_team_list(team_list):\n",
    "    seen = set()\n",
    "    cleaned = []\n",
    "    for item in team_list:\n",
    "        if item is not None and pd.notna(item) and item not in seen:\n",
    "            seen.add(item)\n",
    "            cleaned.append(item)\n",
    "    return cleaned\n",
    "\n",
    "# Apply the functions\n",
    "network_df['Team'] = network_df['Team'].apply(parse_team)\n",
    "network_df['CleanedTeam'] = network_df['Team'].apply(clean_team_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5a7ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure ReferencedWorks is parsed as a list (like we did with Team)\n",
    "def parse_references(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return [val]\n",
    "\n",
    "network_df['ReferencedWorks'] = network_df['ReferencedWorks'].apply(parse_references)\n",
    "\n",
    "# Step 1: Build a mapping from OpenAlex_ID to CleanedTeam\n",
    "id_to_teams = network_df.set_index('OpenAlex_ID')['CleanedTeam'].to_dict()\n",
    "\n",
    "# Step 2: For each row, check which other rows cite this one's OpenAlex_ID\n",
    "# We'll reverse the logic: For each publication, collect the teams from rows where this ID appears in their ReferencedWorks\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a mapping from OpenAlex_ID to list of citing teams\n",
    "teams_that_cited = defaultdict(list)\n",
    "\n",
    "for _, row in network_df.iterrows():\n",
    "    citing_teams = row['CleanedTeam']\n",
    "    for ref_id in row['ReferencedWorks']:\n",
    "        if pd.notna(ref_id):\n",
    "            teams_that_cited[ref_id].extend(citing_teams)\n",
    "\n",
    "# Step 3: Assign to new column, removing duplicates\n",
    "def get_citing_teams(pub_id):\n",
    "    raw_teams = teams_that_cited.get(pub_id, [])\n",
    "    seen = set()\n",
    "    return [team for team in raw_teams if pd.notna(team) and not (team in seen or seen.add(team))]\n",
    "\n",
    "network_df['TeamsThatCited'] = network_df['OpenAlex_ID'].apply(get_citing_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "093dcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create lookup from OpenAlex_ID to CleanedTeam\n",
    "id_to_teams = network_df.set_index('OpenAlex_ID')['CleanedTeam'].to_dict()\n",
    "\n",
    "# Step 2: Define functions to compute the new columns\n",
    "def get_referenced_teams(ref_list):\n",
    "    all_teams = []\n",
    "    for ref_id in ref_list:\n",
    "        if ref_id in id_to_teams:\n",
    "            teams = id_to_teams[ref_id]\n",
    "            if isinstance(teams, list):\n",
    "                all_teams.extend([t for t in teams if pd.notna(t)])\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    return [t for t in all_teams if not (t in seen or seen.add(t))]\n",
    "\n",
    "def get_int_references(ref_list):\n",
    "    return [ref_id for ref_id in ref_list if ref_id in id_to_teams]\n",
    "\n",
    "# Step 3: Apply to the DataFrame\n",
    "network_df['ReferencedTeams'] = network_df['ReferencedWorks'].apply(get_referenced_teams)\n",
    "network_df['IntReferences'] = network_df['ReferencedWorks'].apply(get_int_references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b126132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Fix FirstLastName to be a true list (from its stringified version)\n",
    "def parse_name_list(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, str) and val.strip().startswith('['):\n",
    "        try:\n",
    "            val_cleaned = re.sub(r'\\bnan\\b', 'None', val)\n",
    "            parsed = ast.literal_eval(val_cleaned)\n",
    "            return parsed if isinstance(parsed, list) else []\n",
    "        except Exception:\n",
    "            return []\n",
    "    return [val]\n",
    "\n",
    "network_df['PersonName'] = network_df['PersonName'].apply(parse_name_list)\n",
    "network_df['ReferencedWorks'] = network_df['ReferencedWorks'].apply(parse_name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98c43ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df.to_csv(\"halfway_through+save.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d7eb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_names = network_df.set_index('OpenAlex_ID')['PersonName'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06f16d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_referenced_individuals(ref_list):\n",
    "    names = []\n",
    "    for ref_id in ref_list:\n",
    "        if ref_id in id_to_names:\n",
    "            these_names = id_to_names[ref_id]\n",
    "            if isinstance(these_names, list):\n",
    "                names.extend([n for n in these_names if pd.notna(n)])\n",
    "    # Deduplicate while preserving order\n",
    "    seen = set()\n",
    "    return [name for name in names if name not in seen and not seen.add(name)]\n",
    "\n",
    "network_df['ReferencedIndividuals'] = network_df['ReferencedWorks'].apply(get_referenced_individuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "791a4d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4226263121: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4226263121\n",
      " Failed for W4220677882: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4220677882\n",
      " Failed for W4220677882: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4220677882\n",
      " Failed for W4220677882: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4220677882\n",
      " Failed for W4220677882: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4220677882\n",
      " Failed for W4220677882: 404 Client Error: Not Found for url: https://api.openalex.org/works/W4220677882\n",
      " Filled ReferencedWorks for 28 rows.\n"
     ]
    }
   ],
   "source": [
    "def is_empty(val):\n",
    "    if val is None:\n",
    "        return True\n",
    "    # If it's a list, tuple, or set, check length\n",
    "    if isinstance(val, (list, tuple, set)):\n",
    "        return len(val) == 0\n",
    "    # If it's a numpy array or pandas Series, check length\n",
    "    if hasattr(val, \"__len__\") and not isinstance(val, str):\n",
    "        try:\n",
    "            return len(val) == 0\n",
    "        except Exception:\n",
    "            pass\n",
    "    # If it's a string like '[]', 'nan', etc.\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        return val in ('', '[]', 'nan')\n",
    "    # For scalars, use pd.isna\n",
    "    try:\n",
    "        return pd.isna(val)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "import time\n",
    "\n",
    "filled_count = 0\n",
    "\n",
    "for idx, row in network_df.iterrows():\n",
    "    openalex_id = str(row['OpenAlex_ID']).strip()\n",
    "    if openalex_id.startswith(\"W\") and is_empty(row['ReferencedWorks']):\n",
    "        try:\n",
    "            work = Works()[openalex_id]\n",
    "            if work and 'referenced_works' in work:\n",
    "                network_df.at[idx, 'ReferencedWorks'] = work['referenced_works']\n",
    "                filled_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\" Failed for {openalex_id}: {e}\")\n",
    "        time.sleep(0.25)  # avoid rate limiting\n",
    "\n",
    "print(f\" Filled ReferencedWorks for {filled_count} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e34324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by OpenAlex_ID and collect all unique teams from the Team column\n",
    "def unique_teams(team_series):\n",
    "    seen = set()\n",
    "    teams = []\n",
    "    for val in team_series:\n",
    "        if isinstance(val, list):\n",
    "            for t in val:\n",
    "                if pd.notna(t) and t not in seen:\n",
    "                    teams.append(t)\n",
    "                    seen.add(t)\n",
    "        elif pd.notna(val) and val not in seen:\n",
    "            teams.append(val)\n",
    "            seen.add(val)\n",
    "    return teams\n",
    "\n",
    "cleaned_teams = network_df.groupby('OpenAlex_ID')['Team'].apply(unique_teams)\n",
    "\n",
    "# Assign back to the DataFrame (align by OpenAlex_ID)\n",
    "network_df['CleanedTeams'] = network_df['OpenAlex_ID'].map(cleaned_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82a9700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df['OpenAlex_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34ddf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df.to_csv(\"citation_table_needs_dedup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fec1c5",
   "metadata": {},
   "source": [
    "## Create table for hit citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cee9616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020 = pd.read_csv('citation ranking data/new data/oa_c5rank_2020.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60ee7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = pd.read_csv('citation ranking data/new data/oa_c5rank_2021.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64312d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022 = pd.read_csv('citation ranking data/new data/oa_c5rank_2022.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "570c888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2023 = pd.read_csv('citation ranking data/new data/oa_c5rank_2023.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae55d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2024 = pd.read_csv('citation ranking data/new data/oa_c5rank_2024.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e002e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2025 = pd.read_csv('citation ranking data/new data/oa_c5rank_2025.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89192a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_citation_df = pd.concat([\n",
    "    df2020.assign(source='d0'),\n",
    "    df2021.assign(source='d1'),\n",
    "    df2022.assign(source='d2'),\n",
    "    df2023.assign(source='d3'),\n",
    "    df2024.assign(source='d4'),\n",
    "    df2025.assign(source='d5')\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ee4cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_citation_df['OpenAlex_ID'] = 'W' + combined_citation_df['PublicationId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c19cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_citation_df.to_csv('hit_citation_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8be1ad4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublicationId</th>\n",
       "      <th>TopicId</th>\n",
       "      <th>SubFieldId</th>\n",
       "      <th>FieldId</th>\n",
       "      <th>Year</th>\n",
       "      <th>C5</th>\n",
       "      <th>TopicIdC5Rank</th>\n",
       "      <th>SubFieldIdC5Rank</th>\n",
       "      <th>FieldIdC5Rank</th>\n",
       "      <th>source</th>\n",
       "      <th>OpenAlex_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000632562</td>\n",
       "      <td>11185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.989699</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>d0</td>\n",
       "      <td>W3000632562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000632562</td>\n",
       "      <td>11007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.977364</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>d0</td>\n",
       "      <td>W3000632562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000632562</td>\n",
       "      <td>11225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.997150</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>d0</td>\n",
       "      <td>W3000632562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3034450003</td>\n",
       "      <td>11873</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.997792</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>d0</td>\n",
       "      <td>W3034450003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3034450003</td>\n",
       "      <td>12146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.998762</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>0.993975</td>\n",
       "      <td>d0</td>\n",
       "      <td>W3034450003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PublicationId  TopicId  SubFieldId  FieldId  Year     C5  TopicIdC5Rank  \\\n",
       "0     3000632562    11185           0        0  2020  131.0       0.989699   \n",
       "1     3000632562    11007           0        0  2020  131.0       0.977364   \n",
       "2     3000632562    11225           0        0  2020  131.0       0.997150   \n",
       "3     3034450003    11873           0        0  2020  122.0       0.997792   \n",
       "4     3034450003    12146           0        0  2020  122.0       0.998762   \n",
       "\n",
       "   SubFieldIdC5Rank  FieldIdC5Rank source  OpenAlex_ID  \n",
       "0          0.994733       0.994733     d0  W3000632562  \n",
       "1          0.994734       0.994734     d0  W3000632562  \n",
       "2          0.994734       0.994734     d0  W3000632562  \n",
       "3          0.993974       0.993974     d0  W3034450003  \n",
       "4          0.993975       0.993975     d0  W3034450003  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_citation_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
